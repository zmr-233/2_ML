{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908b9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(tmp1):\n",
    "    import subprocess\n",
    "    import shlex  # 导入 shlex 模块\n",
    "    # 使用 shlex.quote 来转义 inp 字符串\n",
    "    tmp2 = str(tmp1)\n",
    "    safe_str = shlex.quote(tmp2)\n",
    "    subprocess.run('echo {} | wclip'.format(safe_str), shell=True)  \n",
    "\n",
    "def cvin(k):\n",
    "    clip(In[k])\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#格式化输出\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530ba1b2",
   "metadata": {},
   "source": [
    "### 1.马尔可夫过程\n",
    "如果要用强化学习去解决一个实际问题，第一步要做的事情就是把这个实际问题抽象为一个马尔可夫决策过程\n",
    "\n",
    "#### 随机过程\n",
    "指某时刻t取值用向量表示$S_{t}$，而该状态取决于t时刻之前的状态，记作$P(S_{t+1}|S_{1},\\ldots ,S_{t})$\n",
    "\n",
    "#### 马尔可夫性质\n",
    "当且仅当某时刻的状态只取决于上一时刻的状态时，一个随机过程被称为具有马尔可夫性质，记作$P(S_{t+1}|S_{t})= P(S_{t+1}|S_{1},\\ldots ,S_{t})$——下一个状态完全取决于当前状态，通过这种链式关系，可以大大简化运算(因为不需要知道所有历史信息)\n",
    "\n",
    "#### 马尔可夫过程\n",
    "马尔可夫过程 (Markov process) 指具有马尔可夫性质的随机过程，也被称为马尔可夫链 (Markov chain) 。我们通常用元组 $\\langle\\mathcal{S}, \\mathcal{P}\\rangle$ 描述一个马尔可夫过程，其中 $\\mathcal{S}$ 是有限数量的状态集合， $\\mathcal{P}$ 是状态转移矩 阵 (state transition matrix) 。假设一共有 n 个状态，此时 $\\mathcal{S}=\\left\\{s_{1}, s_{2}, \\ldots, s_{n}\\right\\}$ 。状态转移矩阵 $\\mathcal{P}$ 定义了 所有状态对之间的转移概率，即:\n",
    "$$\n",
    "\\\\\\\\\\mathcal{P}=\\left[\\begin{array}{ccc}\\\\P\\left(s_{1} \\mid s_{1}\\right) & \\cdots & P\\left(s_{n} \\mid s_{1}\\right) \\\\\\\\\\vdots & \\ddots & \\vdots \\\\\\\\P\\left(s_{1} \\mid s_{n}\\right) & \\cdots & P\\left(s_{n} \\mid s_{n}\\right)\\\\\\end{array}\\right]\\\\\\\\\n",
    "$$\n",
    "矩阵 $\\mathcal{P}$ 中第 i 行第 j 列元素 $P\\left(s_{j} \\mid s_{i}\\right)=P\\left(S_{t+1}=s_{j} \\mid S_{t}=s_{i}\\right)$ 表示从状态$ s_{i}$ 转移到状态 $s_{j}$ 的概率，我们称 $P\\left(s^{\\prime} \\mid s\\right)$ 为状态转移函数。从某个状态出发，到达其他状态的概率和必须为 1 ，即状态转移矩阵 $\\mathcal{P}$ 的每一 行的和为 1 。\n",
    "\n",
    "给定一个马尔可夫过程，我们就可以从某个状态出发，根据它的状态转移矩阵生成一个**状态序列（episode）**，这个步骤也被叫做**采样（sampling）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cbcc6a",
   "metadata": {},
   "source": [
    "### 2.马尔可夫奖励过程 MRP\n",
    "\n",
    "在马尔可夫过程的基础上加入奖励函数 $r$ 和折扣因子 $\\gamma$，就可以得到马尔可夫奖励过程（Markov reward process）。\n",
    "一个马尔可夫奖励过程由 $ \\langle\\mathcal{S}, \\mathcal{P}, r, \\gamma\\rangle $ 构成，各个组成元素的含义如下所示。\n",
    "- $\\mathcal{S}$ 是有限状态的集合\n",
    "- $\\mathcal{P}$ 是状态转移矩阵\n",
    "- $r$ 是**奖励函数**，某个状态 $s$ 的奖励 $r(s)$ 指转移到该状态时可以获得奖励的期望\n",
    "- $\\gamma$ 是折扣因子 (discount factor)， $\\gamma$ 的取值范围为 [0,1) 。\n",
    "\n",
    "引入折扣因子的理由为远期利益具有一定不确定性，有时我们更希望能够尽快获得一些奖励，所以我们需要对远期利益打一些折扣。\n",
    "- 接近 1 的 $\\gamma$ 更关注长期的累计奖励\n",
    "- 接近 0 的 $\\gamma$ 更考虑短期奖励\n",
    "\n",
    "#### 2.1回报\n",
    "在一个马尔可夫奖励过程中，从第t时刻状态 $S_{t}$ 开始，直到终止状态时，所有奖励的衰减之和称为回报 $G_{t}$ (Return)， 公式如下：\n",
    "$$\n",
    "G_{t}=R_{t}+\\gamma R_{t+1}+\\gamma^{2} R_{t+2}+\\cdots=\\sum_{k=0}^{\\infty} \\gamma^{k} R_{t+k} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b37ee132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "# 定义状态转移概率矩阵P\n",
    "P = [\n",
    "    [0.9, 0.1, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.5, 0.0, 0.5, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.6, 0.0, 0.4],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.3, 0.7],\n",
    "    [0.0, 0.2, 0.3, 0.5, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "]\n",
    "P = np.array(P)\n",
    "\n",
    "rewards = [-1, -2, -2, 10, 1, 0]  # 定义奖励函数\n",
    "gamma = 0.5  # 定义折扣因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daecfea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给定一条序列,计算从某个索引（起始状态）开始到序列最后（终止状态）得到的回报\n",
    "def compute_return(start_index, chain, gamma):\n",
    "    G = 0\n",
    "    for i in reversed(range(start_index, len(chain))):\n",
    "        G = gamma * G + rewards[chain[i] - 1]\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9055459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据本序列计算得到回报为：-2.5。\n"
     ]
    }
   ],
   "source": [
    "# 一个状态序列,s1-s2-s3-s6\n",
    "chain = [1, 2, 3, 6]\n",
    "start_index = 0\n",
    "G = compute_return(start_index, chain, gamma)\n",
    "print(\"根据本序列计算得到回报为：%s。\" % G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bb1843",
   "metadata": {},
   "source": [
    "#### 2.2价值函数V(s)\n",
    "在马尔可夫奖励过程中，一个状态的期望回报（即从这个状态出发的未来累积奖励的期望）被称为这个状态的**价值（value）**。所有状态的价值就组成了**价值函数（value function）**，价值函数的输入为某个状态，输出为这个状态的价值：\n",
    "\n",
    "$V(s) = \\mathbb{E}\\left[G_{t} \\mid S_{t}=s\\right]$\n",
    "\n",
    "$= \\mathbb{E}\\left[R_{t}+\\gamma R_{t+1}+\\gamma^{2} R_{t+2}+\\ldots \\mid S_{t}=s\\right]$\n",
    "\n",
    "$= \\mathbb{E}\\left[R_{t}+\\gamma\\left(R_{t+1}+\\gamma R_{t+2}+\\ldots\\right) \\mid S_{t}=s\\right]$\n",
    "\n",
    "$= \\mathbb{E}\\left[R_{t}+\\gamma G_{t+1} \\mid S_{t}=s\\right]$\n",
    "\n",
    "$= \\mathbb{E}\\left[R_{t}+\\gamma V\\left(S_{t+1}\\right) \\mid S_{t}=s\\right]$\n",
    "\n",
    "在上式的最后一个等号中，一方面，即时奖励的期望正是奖励函数的输出，即 $\\mathbb{E}\\left[R_{t} \\mid S_{t}=s\\right]=r(s)$；\n",
    "另一方面，等式中剩余部分 $\\mathbb{E}\\left[\\gamma V\\left(S_{t+1}\\right) \\mid S_{t}=s\\right]$ 可以根据从状态 $s$ 出发的转移概率得到，即可以得到:\n",
    "$$\n",
    "V(s)=r(s)+\\gamma \\sum_{s^{\\prime} \\in S} p\\left(s^{\\prime} \\mid s\\right) V\\left(s^{\\prime}\\right)\n",
    "$$\n",
    "上式就是马尔可夫奖励过程中非常有名的**贝尔曼方程（Bellman equation）**，对每一个状态都成立。若一个马尔可夫奖励过程一共有 $n$ 个状态，即 $\\mathcal{S}=\\left\\{s_{1}, s_{2}, \\ldots, s_{n}\\right\\}$，我们将所有状态的价值表示成一个列向量 $\\mathcal{V}=\\left[V\\left(s_{1}\\right), V\\left(s_{2}\\right), \\ldots, V\\left(s_{n}\\right)\\right]^{T}$，同理，将奖励函数写成一个列向量\n",
    "$\\mathcal{R}=\\left[r\\left(s_{1}\\right), r\\left(s_{2}\\right), \\ldots, r\\left(s_{n}\\right)\\right]^{T}$。于是我们可以将贝尔曼方程写成矩阵的形式:\n",
    "$$\n",
    "\\mathcal{V}=\\mathcal{R}+\\gamma \\mathcal{P} \\mathcal{V}\n",
    "$$\n",
    "$$\n",
    "{\\left[\\begin{array}{c}\n",
    "V\\left(s_{1}\\right) \\\\\n",
    "V\\left(s_{2}\\right) \\\\\n",
    "\\ldots \\\\\n",
    "V\\left(s_{n}\\right)\n",
    "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
    "r\\left(s_{1}\\right) \\\\\n",
    "r\\left(s_{2}\\right) \\\\\n",
    "\\ldots \\\\\n",
    "r\\left(s_{n}\\right)\n",
    "\\end{array}\\right]+\\gamma\\left[\\begin{array}{cccc}\n",
    "P\\left(s_{1} \\mid s_{1}\\right) & p\\left(s_{2} \\mid s_{1}\\right) & \\ldots & P\\left(s_{n} \\mid s_{1}\\right) \\\\\n",
    "P\\left(s_{1} \\mid s_{2}\\right) & P\\left(s_{2} \\mid s_{2}\\right) & \\ldots & P\\left(s_{n} \\mid s_{2}\\right) \\\\\n",
    "\\ldots & & & \\\\\n",
    "P\\left(s_{1} \\mid s_{n}\\right) & P\\left(s_{2} \\mid s_{n}\\right) & \\ldots & P\\left(s_{n} \\mid s_{n}\\right)\n",
    "\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "V\\left(s_{1}\\right) \\\\\n",
    "V\\left(s_{2}\\right) \\\\\n",
    "\\ldots \\\\\n",
    "V\\left(s_{n}\\right)\n",
    "\\end{array}\\right]}\n",
    "$$\n",
    "我们可以直接根据矩阵运算求解，得到以下解析解:\n",
    "\n",
    "$\\mathcal{V} =\\mathcal{R}+\\gamma \\mathcal{P} \\mathcal{V}$\n",
    "$(I-\\gamma \\mathcal{P}) \\mathcal{V} =\\mathcal{R}$\n",
    "$\\mathcal{V} =(I-\\gamma \\mathcal{P})^{-1} \\mathcal{R}$\n",
    "\n",
    "以上解析解的计算复杂度是 $O\\left(n^{3}\\right)$，其中 $n$ 是状态个数，因此这种方法只适用很小的马尔可夫奖励过程。\n",
    "求解较大规模的马尔可夫奖励过程中的价值函数时，可以使用**动态规划（dynamic programming算法**、**蒙特卡洛方法（Monte-Carlo method）**和**时序差分（temporal difference）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de48465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRP中每个状态价值分别为\n",
      " [[-2.02 ]\n",
      " [-2.215]\n",
      " [ 1.161]\n",
      " [10.538]\n",
      " [ 3.587]\n",
      " [ 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "def compute(P, rewards, gamma, states_num):\n",
    "    ''' 利用贝尔曼方程的矩阵形式计算解析解,states_num是MRP的状态数 '''\n",
    "    rewards = np.array(rewards).reshape((-1, 1))  #将rewards写成列向量形式\n",
    "    value = np.dot(np.linalg.inv(np.eye(states_num, states_num) - gamma * P),\n",
    "                   rewards)\n",
    "    return value\n",
    "\n",
    "\n",
    "V = compute(P, rewards, gamma, 6)\n",
    "print(\"MRP中每个状态价值分别为\\n\", V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8cdea4",
   "metadata": {},
   "source": [
    "可以用贝尔曼方程进行验证：\n",
    "$$\n",
    "V(s_{4})=r(s_{4})+\\gamma \\sum_{s^{\\prime} \\in S} p\\left(s^{\\prime} \\mid s_{4}\\right) V\\left(s^{\\prime}\\right)\n",
    "$$\n",
    "$10.54 = 10 + 0.5 \\times (0.7 \\times 0+0.3 \\times 3.59)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911218f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.马尔可夫决策过程 MDP\n",
    "马尔可夫过程和马尔可夫奖励过程都是自发改变的随机过程；而如果有一个外界的\"刺激\"来共同改变这个随机过程，就有了**马尔可夫决策过程（Markov decision process，MDP）**\n",
    "将这个来自外界的刺激称为**智能体/代理（agent）**的动作，一个马尔科夫决策过程由元组$ \\langle\\mathcal{S}, \\mathcal{A}, \\mathcal{P}, r, \\gamma\\rangle $构成\n",
    "- $\\mathcal{S}$ 状态集合\n",
    "- $\\mathcal{A}$->新增 动作集合\n",
    "- $\\mathcal{P}$->$P(s^{\\prime} | s,a)$ 是**状态转移函数**，表示在状态s执行a后到达$s^{\\prime}$的概率(可以为1)\n",
    "- $r$ -> $r(s,a)$ 是**奖励函数**,此时的奖励同时取决于状态s和下一步动作a，可以退化为$r(s)$\n",
    "- $\\gamma$ 是折扣因子\n",
    "\n",
    "MDP 与 MRP 非常相像，只是多了动作$a$作为自变量\n",
    "**_注意：不再使用MRP的状态转移矩阵，而是直接使用状态转移函数，可以处理非离散值_**\n",
    "\n",
    "#### 3.1策略 $\\pi$\n",
    "智能体的策略（Policy）通常用$\\pi$表示，写作$\\pi(a | s)=P(A_{t}=a | S_{t} = s)$的形式，并细分为：\n",
    "- **_确定性策略（deterministic policy）_** 每个状态时只输出一个确定性的动作，即只有该动作的概率为 1，其他动作的概率为 0\n",
    "- **_随机性策略（stochastic policy）_** 每个状态时输出的是关于动作的概率分布\n",
    "\n",
    "#### 3.2状态价值函数$V^{\\pi}(s)$\n",
    "<u>**_注意：此时的价值函数与策略有关——不同的策略下，同一个状态的价值是不同的->因为不同的策略会带来不同的动作，从而有不同的奖励_**</u>\n",
    "\n",
    "我们用 $V^{\\pi}(s)$ 表示在 MDP 中基于策略 $\\pi$ 的**状态价值函数（state-value function）**，定义为从状态 $s$ 出发遵循策略 $\\pi$ 能获得的期望回报，数学表达为:\n",
    "$$\n",
    "V^{\\pi}(s)=\\mathbb{E}_{\\pi}\\left[G_{t} \\mid S_{t}=s\\right]\n",
    "$$\n",
    "\n",
    "#### 3.3动作价值函数$Q^{\\pi}(s,a)$\n",
    "由于动作的存在额外定义一个**动作价值函数 (action-value function）**。我们用 $Q^{\\pi}(s, a)$ 表示在 MDP 遵循策略 $\\pi$ 时，对当前状态 $s$ 执行动作 $a$ 得到的期望回报:\n",
    "$$\n",
    "Q^{\\pi}(s, a)=\\mathbb{E}_{\\pi}\\left[G_{t} \\mid S_{t}=s, A_{t}=a\\right]\n",
    "$$\n",
    "1. **_状态价值函数和动作价值函数之间的关系：_** 在使用策略 $\\pi$ 中，状态 $s$ 的价值等于在该状态下基于策略 $\\pi$ 采取所有动作的概率与相应的价值相乘再求和的结果:\n",
    "$$\n",
    "V^{\\pi}(s)=\\sum_{a \\in A} \\pi(a \\mid s) Q^{\\pi}(s, a)\n",
    "$$\n",
    "2. **_使用策略 $\\pi$ 时，状态 $s$ 下采取动作 $a$ 的价值:_** 等于即时奖励加上经过衰减后的所有可能的下一个状态的状态转移概率与相应的价值的乘积:\n",
    "$$\n",
    "Q^{\\pi}(s, a)=r(s, a)+\\gamma \\sum_{s^{\\prime} \\in S} P\\left(s^{\\prime} \\mid s, a\\right) V^{\\pi}\\left(s^{\\prime}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b146de8a",
   "metadata": {},
   "source": [
    "### 4.贝尔曼期望方程\n",
    "> **价值函数和贝尔曼方程是强化学习非常重要的组成部分，之后的一些强化学习算法都是据此推导出来的，需要明确掌握！**\n",
    "\n",
    "在贝尔曼方程中加上“期望”二字是为了与接下来的贝尔曼最优方程进行区分：\n",
    "$$\n",
    "\\begin{aligned} V^{\\pi}(s) & =\\mathbb{E}_{\\pi}\\left[R_{t}+\\gamma V^{\\pi}\\left(S_{t+1}\\right) \\mid S_{t}=s\\right] \\\\ & =\\sum_{a \\in A} \\pi(a \\mid s)\\left(r(s, a)+\\gamma \\sum_{s^{\\prime} \\in S} p\\left(s^{\\prime} \\mid s, a\\right) V^{\\pi}\\left(s^{\\prime}\\right)\\right) \\\\ Q^{\\pi}(s, a) & =\\mathbb{E}_{\\pi}\\left[R_{t}+\\gamma Q^{\\pi}\\left(S_{t+1}, A_{t+1}\\right) \\mid S_{t}=s, A_{t}=a\\right] \\\\ & =r(s, a)+\\gamma \\sum_{s^{\\prime} \\in S} p\\left(s^{\\prime} \\mid s, a\\right) \\sum_{a^{\\prime} \\in A} \\pi\\left(a^{\\prime} \\mid s^{\\prime}\\right) Q^{\\pi}\\left(s^{\\prime}, a^{\\prime}\\right)\\end{aligned}\n",
    "$$\n",
    "需要注意，并非在每个状态都能采取所有动作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f8f140",
   "metadata": {},
   "source": [
    "#### 4.1MDP近似求解\n",
    "直接为MDP找到解析解是计算密集型的，特别是当状态和动作空间很大时。在这种情况下，通常会使用近似方法或学习算法：\n",
    "迭代方法用于求解MDP的最优策略。最常用的两种迭代方法是**值迭代**和**策略迭代**。下面是这两种方法的详细描述：\n",
    "\n",
    "1. 值迭代 (Value Iteration)\n",
    "值迭代是一种迭代算法，用于计算每个状态的最优值函数。该方法基于贝尔曼最优性方程，以下是算法步骤：\n",
    "1. 初始化值函数，例如 $V(s) = 0$ 对于所有状态 $s$。\n",
    "2. 迭代更新值函数直到收敛：\n",
    "   $$V_{\\text{new}}(s) = \\max_{a \\in A} \\left( R(s,a) + \\gamma \\sum_{s' \\in S} P(s'|s,a) V(s') \\right)$$\n",
    "3. 重复步骤2，直到 $V$ 的变化小于某个阈值或达到最大迭代次数。\n",
    "4. 一旦值函数收敛，可以通过贪婪策略得到最优策略：\n",
    "   $$\\pi^*(s) = \\arg\\max_{a \\in A} \\left( R(s,a) + \\gamma \\sum_{s' \\in S} P(s'|s,a) V^*(s') \\right)$$\n",
    "\n",
    "2. 策略迭代 (Policy Iteration)\n",
    "策略迭代包括策略评估和策略改进两个步骤。以下是算法步骤：\n",
    "1. 随机初始化一个策略 $\\pi$。\n",
    "2. **策略评估**：为给定的策略 $\\pi$ 计算值函数 $V^\\pi$，直到收敛。\n",
    "   $$V^\\pi(s) = \\sum_{a \\in A} \\pi(a|s) \\left( R(s,a) + \\gamma \\sum_{s' \\in S} P(s'|s,a) V^\\pi(s') \\right)$$\n",
    "3. **策略改进**：更新策略以使其更接近最优策略。\n",
    "   $$\\pi_{\\text{new}}(s) = \\arg\\max_{a \\in A} \\left( R(s,a) + \\gamma \\sum_{s' \\in S} P(s'|s,a) V^\\pi(s') \\right)$$\n",
    "4. 如果新策略与旧策略相同，停止迭代。否则，返回步骤2。\n",
    "\n",
    "在实际应用中，策略迭代通常比值迭代收敛得更快，尤其是当策略空间相对较小时。但是，策略迭代的每次迭代需要评估策略，这在计算上可能会更加昂贵。选择哪种方法取决于具体的应用和可用的计算资源。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2827ee",
   "metadata": {},
   "source": [
    "#### 4.2边缘转移概率 MDP->MRP\n",
    "给定一个 MDP 和一个策略$\\pi$，能否将其转换为一个MRP？策略是将动作进行**边缘化(marginalization)**，就可以得到没有动作的MRP\n",
    "1. **奖励函数$r^{\\prime}(s)$:**\n",
    "$$\n",
    "r^{\\prime}(s)=\\sum_{a \\in \\mathcal{A}} \\pi(a | s)r(s,a)\n",
    "$$\n",
    "2. **状态转移函数$P^{\\prime}(s^{\\prime}|s)$:**\n",
    "$$\n",
    "P^{\\prime}(s^{\\prime}|s)=\\sum_{a \\in \\mathcal{A}}\\pi(a|s)P(s^{\\prime}|s,a)\n",
    "$$\n",
    "由此可以构建出一个MRP $ \\langle\\mathcal{S},\\mathcal{P^{\\prime}}, r^{\\prime}, \\gamma\\rangle $，按照MRP的贝尔曼方程进行求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c508ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "036b856e",
   "metadata": {},
   "source": [
    " MRP 解析解的方法在状态动作集合比较大的时候不是很适用，3.5 节将介绍用蒙特卡洛方法来近似估计这个价值函数，用蒙特卡洛方法的好处在于我们不需要知道 MDP 的状态转移函数和奖励函数，它可以得到一个近似值，并且采样数越多越准确\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72efe232",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = ['s1','s2','s3','s4','s5']\n",
    "A = ['保持','前往','概率前往']\n",
    "P ={\n",
    "    \"s1\":{\n",
    "        \"保持\":{\"s1\":1.0},\n",
    "        \"前往\":{\"s2\":1.0}\n",
    "    },\n",
    "    \"s2\":{\n",
    "        \"前往\":{\"s1\":1.0,\"s3\":1.0},\n",
    "    },\n",
    "    \"s3\":{\n",
    "        \"前往\":{\"s5\":1.0,\"s4\":1.0},\n",
    "    },\n",
    "    \"s4\":{\n",
    "        \"前往\":{\"s5\":1.0,},\n",
    "        \"概率前往\":{\"s2\":0.2,\"s3\":0.4,\"s4\":0.4,},\n",
    "    },\n",
    "}\n",
    "R ={\n",
    "    \"s1\":{\n",
    "        \"保持\":{\"s1\":-1},\n",
    "        \"前往\":{\"s2\":0}\n",
    "    },\n",
    "    \"s2\":{\n",
    "        \"前往\":{\"s1\":-1,\"s3\":-2},\n",
    "    },\n",
    "    \"s3\":{\n",
    "        \"前往\":{\"s5\":0,\"s4\":-2},\n",
    "    },\n",
    "    \"s4\":{\n",
    "        \"前往\":{\"s5\":10,},\n",
    "        \"概率前往\":1,\n",
    "    },\n",
    "}\n",
    "gamma = 0.5\n",
    "\n",
    "\n",
    "# 策略\n",
    "Pi_1 ={\n",
    "    \"s1\":{\n",
    "        \"保持\":{\"s1\":0.5},\n",
    "        \"前往\":{\"s2\":0.5}\n",
    "    },\n",
    "    \"s2\":{\n",
    "        \"前往\":{\"s1\":0.5,\"s3\":0.5},\n",
    "    },\n",
    "    \"s3\":{\n",
    "        \"前往\":{\"s5\":0.5,\"s4\":0.5},\n",
    "    },\n",
    "    \"s4\":{\n",
    "        \"前往\":{\"s5\":0.5,},\n",
    "        \"概率前往\":0.5,\n",
    "    },\n",
    "}\n",
    "Pi_2 ={\n",
    "    \"s1\":{\n",
    "        \"保持\":{\"s1\":0.6},\n",
    "        \"前往\":{\"s2\":0.4}\n",
    "    },\n",
    "    \"s2\":{\n",
    "        \"前往\":{\"s1\":0.3,\"s3\":0.7},\n",
    "    },\n",
    "    \"s3\":{\n",
    "        \"前往\":{\"s5\":0.5,\"s4\":0.5},\n",
    "    },\n",
    "    \"s4\":{\n",
    "        \"前往\":{\"s5\":0.1,},\n",
    "        \"概率前往\":0.9,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dff343",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```\n",
    "def marginal_reward(state, policy, R):\n",
    "    reward = 0\n",
    "    for action in policy[state]:\n",
    "        if isinstance(policy[state][action], dict):\n",
    "            action_prob = sum(policy[state][action].values())\n",
    "        else:\n",
    "            action_prob = policy[state][action]\n",
    "        for next_state in R[state][action]:\n",
    "            reward += action_prob * R[state][action][next_state]\n",
    "    return reward\n",
    "\n",
    "def marginal_transition(state, next_state, policy, P):\n",
    "    prob = 0\n",
    "    for action in policy[state]:\n",
    "        if isinstance(policy[state][action], dict):\n",
    "            action_prob = policy[state][action].get(next_state, 0)\n",
    "        else:\n",
    "            action_prob = policy[state][action]\n",
    "        prob += action_prob * P[state][action].get(next_state, 0)\n",
    "    return prob\n",
    "\n",
    "def compute_marginal_MRP(policy, P, R):\n",
    "    marginal_R = {}\n",
    "    marginal_P = {}\n",
    "    for state in S:\n",
    "        if state in policy:\n",
    "            marginal_R[state] = marginal_reward(state, policy, R)\n",
    "            marginal_P[state] = {}\n",
    "            for next_state in S:\n",
    "                marginal_P[state][next_state] = marginal_transition(state, next_state, policy, P)\n",
    "        else:\n",
    "            # Handling states not defined in the policy\n",
    "            marginal_R[state] = 0\n",
    "            marginal_P[state] = {s: 0 for s in S}\n",
    "    return marginal_R, marginal_P\n",
    "\n",
    "# Computing marginal MRP for the policies again\n",
    "marginal_R_Pi_1, marginal_P_Pi_1 = compute_marginal_MRP(Pi_1, P, R)\n",
    "marginal_R_Pi_2, marginal_P_Pi_2 = compute_marginal_MRP(Pi_2, P, R)\n",
    "\n",
    "print(marginal_R_Pi_1)\n",
    "print('+++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "print(marginal_P_Pi_1)\n",
    "print('+++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "print(marginal_R_Pi_2)\n",
    "print('+++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "print(marginal_P_Pi_2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa760d",
   "metadata": {},
   "source": [
    "```\n",
    "def reward_to_list(marginal_R):\n",
    "    return [marginal_R[state] for state in S]\n",
    "\n",
    "def transition_to_matrix(marginal_P):\n",
    "    matrix = []\n",
    "    for state in S:\n",
    "        row = [marginal_P[state][next_state] for next_state in S]\n",
    "        matrix.append(row)\n",
    "    return matrix\n",
    "\n",
    "# Converting the marginal rewards and transitions for Pi_1 and Pi_2 to lists and matrices\n",
    "R_list_Pi_1 = reward_to_list(marginal_R_Pi_1)\n",
    "P_matrix_Pi_1 = transition_to_matrix(marginal_P_Pi_1)\n",
    "\n",
    "R_list_Pi_2 = reward_to_list(marginal_R_Pi_2)\n",
    "P_matrix_Pi_2 = transition_to_matrix(marginal_P_Pi_2)\n",
    "\n",
    "R_list_Pi_1 = np.array(R_list_Pi_1)\n",
    "P_matrix_Pi_1= np.array(P_matrix_Pi_1)\n",
    "R_list_Pi_2= np.array(R_list_Pi_2)\n",
    "P_matrix_Pi_2= np.array(P_matrix_Pi_2)\n",
    "\n",
    "R_list_Pi_1,P_matrix_Pi_1,R_list_Pi_2,P_matrix_Pi_2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba94e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1440b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_MRP = [\n",
    "    [0.5, 0.5, 0.0, 0.0, 0.0],\n",
    "    [0.5, 0.0, 0.5, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "    [0.0, 0.1, 0.2, 0.2, 0.5],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "]\n",
    "R_MRP = [-0.5, -1.5, -1.0, 5.5, 0]\n",
    "P_MRP = np.array(P_MRP)\n",
    "R_MRP = np.array(R_MRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce27d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_BellEqua(P,R,gamma):\n",
    "    sta = P.shape[0] #状态数量\n",
    "    return np.linalg.inv(np.eye(sta,sta)-gamma*P).dot(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "154b00dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.226, -1.677,  0.519,  6.076,  0.   ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_BellEqua(P_MRP,R_MRP,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "838bce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s2': 1.0}\n"
     ]
    }
   ],
   "source": [
    "s = S[np.random.randint(4)]\n",
    "a = np.random.choice(list(P[s].keys()))\n",
    "print(P[s][a])\n",
    "next_s = np.random.choice(list(P[s][a].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6116d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDP = (S,A,P,R,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab5d2c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['前往', '概率前往']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1, 0.9]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pi = Pi_2\n",
    "s = 's4'\n",
    "action = list(Pi[s].keys())\n",
    "print(action)\n",
    "[sum(Pi[s][i].values()) if isinstance(Pi[s][i],dict) else Pi[s][i] for i in action]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd935294",
   "metadata": {},
   "source": [
    "### 5.蒙特卡洛采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2b35532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MDP_sample(MDP, Pi, *, step_max=100, n=100):\n",
    "    S, A, P, R, gamma = MDP\n",
    "    episodes = []\n",
    "    for _ in range(n):\n",
    "        episode = []\n",
    "        step_n = 0\n",
    "        s = S[np.random.randint(len(S)-1)]\n",
    "        while s != \"s5\" and step_n <= step_max:\n",
    "            step_n += 1\n",
    "            # 使用策略 Pi 选择动作\n",
    "            action = list(Pi[s].keys())\n",
    "            prob_action = [sum(Pi[s][i].values()) if isinstance(Pi[s][i],dict) else Pi[s][i] for i in action]\n",
    "            a = np.random.choice(action,p=prob_action)\n",
    "    \n",
    "            if a == \"概率前往\": \n",
    "                ns = list(P[s][a].keys())\n",
    "                prob_ns = list(P[s][a].values())\n",
    "                next_s = np.random.choice(ns, p=prob_ns)\n",
    "                r = R[s][a]\n",
    "            else:\n",
    "                ns = list(Pi[s][a].keys())\n",
    "                prob_ns = np.array(list(Pi[s][a].values()))\n",
    "                prob_ns = prob_ns / np.sum(prob_ns) #易错：归一化\n",
    "                next_s = np.random.choice(ns, p=prob_ns)  \n",
    "                r = R[s][a][next_s]\n",
    "            p = P[s][a][next_s]\n",
    "            episode.append((s, a, next_s, r))\n",
    "        episodes.append(episode)\n",
    "    return episodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4a8f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_Vs(episodes,V,N,gamma):\n",
    "    for epi in episodes:\n",
    "        G = 0\n",
    "        for i in range(len(epi)-1,-1,-1): #从后往前计算\n",
    "            (s,a,next_s,r) = epi[i]\n",
    "            G = r + gamma*G\n",
    "            N[s] = N[s] + 1\n",
    "            V[s] = V[s] + 1/N[s] * (G - V[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e3ef394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s1': -0.9888157694617663, 's2': -2.9742314270293644, 's3': -1.982136726819825, 's4': 10.920994718396887, 's5': 0}\n",
      "{'s1': 254722, 's2': 252197, 's3': 256338, 's4': 246743, 's5': 0}\n"
     ]
    }
   ],
   "source": [
    "episodes = MDP_sample(MDP,Pi_1,step_max=100,n=10000)\n",
    "gamma = 0.5\n",
    "V = {\"s1\": 0, \"s2\": 0, \"s3\": 0, \"s4\": 0, \"s5\": 0}\n",
    "N = {\"s1\": 0, \"s2\": 0, \"s3\": 0, \"s4\": 0, \"s5\": 0}\n",
    "cal_Vs(episodes, V, N, gamma)\n",
    "print(V)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "355ffd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_Vs(MDP, Pi_1, step_max=10, n=100):\n",
    "    # 初始化\n",
    "    V = {\"s1\": 0, \"s2\": 0, \"s3\": 0, \"s4\": 0, \"s5\": 0}\n",
    "    N = {\"s1\": 0, \"s2\": 0, \"s3\": 0, \"s4\": 0, \"s5\": 0}\n",
    "    gamma = 0.5\n",
    "    \n",
    "    # 用于存储每个状态的V和N值的列表\n",
    "    V_values = {\"s1\": [], \"s2\": [], \"s3\": [], \"s4\": [], \"s5\": []}\n",
    "    N_values = {\"s1\": [], \"s2\": [], \"s3\": [], \"s4\": [], \"s5\": []}\n",
    "    \n",
    "    for i in range(n):\n",
    "        episodes = MDP_sample(MDP,Pi_1,step_max=step_max,n=n)\n",
    "        cal_Vs(episodes, V, N, gamma)\n",
    "        \n",
    "        for s in V:\n",
    "            V_values[s].append(V[s])\n",
    "            N_values[s].append(N[s])\n",
    "            \n",
    "    # 绘制图形\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for s in V:\n",
    "        plt.plot(N_values[s], V_values[s], label=f'V[{s}]')\n",
    "        \n",
    "    plt.xlabel('N[s]')\n",
    "    plt.ylabel('V[s]')\n",
    "    plt.title('V[s] vs N[s]')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 假设您已经定义了MDP_sample, Pi_1, MDP, 和 cal_Vs\n",
    "# 调用函数\n",
    "# plot_Vs(MDP, Pi_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3276cff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_Vs(MDP, Pi_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a3d8f",
   "metadata": {},
   "source": [
    "### 6.占用量度\n",
    "状态访问分布和占用度量是强化学习中两个相关的概念，常用于描述一个策略在环境中的行为。以下是这两个概念的定义和描述：\n",
    "\n",
    "1. **状态访问分布** (State Visitation Distribution):\n",
    "   \n",
    "状态访问分布描述了在给定策略下，一个状态被访问的频率或概率。这通常取决于策略本身以及初始状态分布。例如，考虑一个迷宫问题，某些状态可能经常被访问（例如，迷宫的入口或者交叉点），而其他状态可能很少或从不被访问。状态访问分布会反映出这种差异。\n",
    "   \n",
    "具体地说，状态访问分布 $d(s)$ 可以通过以下公式定义：\n",
    "   \n",
    "$$d(s) = \\sum_{s', a} P(s' \\to s | a) \\pi(a|s') d(s')$$\n",
    "   \n",
    "其中，$P(s' \\to s | a)$ 是从状态 $s'$ 在采取动作 $a$ 后转移到状态 $s$ 的概率，而 $\\pi(a|s')$ 是在状态 $s'$ 下采取动作 $a$ 的概率。\n",
    "\n",
    "2. **占用度量** (Occupancy Measure):\n",
    "\n",
    "占用度量描述了在给定策略下，一个状态-动作对 (state-action pair) 被访问的频率或概率。这可以视为状态访问分布的扩展，因为它不仅考虑了状态，还考虑了在该状态下采取的动作。\n",
    "   \n",
    "具体地说，占用度量 $\\rho(s, a)$ 可以通过以下公式定义：\n",
    "\n",
    "$$\\rho(s, a) = d(s) \\pi(a|s)$$\n",
    "   \n",
    "其中，$d(s)$ 是状态 $s$ 的访问分布，而 $\\pi(a|s)$ 是在状态 $s$ 下采取动作 $a$ 的概率。\n",
    "\n",
    "这两个概念在强化学习中尤为重要，特别是在逆强化学习（Inverse Reinforcement Learning，IRL）中，其中我们试图从观察到的行为中推断出奖励函数。状态访问分布和占用度量提供了关于策略在环境中行为的关键信息，这有助于我们更好地理解和建模该策略。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5546e7d",
   "metadata": {},
   "source": [
    "然后就可以定义一个策略的状态访问分布（state visitation distribution）：\n",
    "$$\n",
    "\\nu^{\\pi}(s)=(1-\\gamma) \\sum_{t=0}^{\\infty} \\gamma^{t} P_{t}^{\\pi}(s)\n",
    "$$\n",
    "其中， $1-\\gamma$ 是用来使得概率加和为 1 的归一化因子。状态访问概率表示一个策略和 MDP 交互会访问到的状态的分布。需要注意的是，理论上在计算该分布时需要交互到无穷步之后，但实际上智能体和 MDP 的交互在一个序列中是有限的。不过我们仍然可以用以上公式来表达状态访问概率的思想，状态访问概率有如下性质:\n",
    "$$\n",
    "\\nu^{\\pi}\\left(s^{\\prime}\\right)=(1-\\gamma) \\nu_{0}\\left(s^{\\prime}\\right)+\\gamma \\int P\\left(s^{\\prime} \\mid s, a\\right) \\pi(a \\mid s) \\nu^{\\pi}(s) d s d a\n",
    "$$\n",
    "$$\n",
    "\\rho^{\\pi}(s, a)=(1-\\gamma) \\sum_{t=0}^{\\infty} \\gamma^{t} P_{t}^{\\pi}(s) \\pi(a \\mid s)\\\n",
    "$$\n",
    "它表示动作状态对 $(s, a)$ 被访问到的概率。二者之间存在如下关系:\n",
    "$$\n",
    "\\rho^{\\pi}(s, a)=\\nu^{\\pi}(s) \\pi(a \\mid s)\n",
    "$$\n",
    "进一步得出如下两个定理：\n",
    "- 定理 1: 智能体分别以策略 $\\pi_{1}$ 和 $\\pi_{2}$ 和同一个 MDP 交互得到的占用度量 $\\rho^{\\pi_{1}}$ 和 $\\rho^{\\pi_{2}}$ 满足\n",
    "$$\\rho^{\\pi_{1}}=\\rho^{\\pi_{2}} \\Longleftrightarrow \\pi_{1}=\\pi_{2}$$\n",
    "\n",
    "- 定理 2：给定一合法占用度量 $\\rho$ ，可生成该占用度量的唯一策略是\n",
    "$$\\pi_{\\rho}=\\frac{\\rho(s, a)}{\\sum_{a^{\\prime}} \\rho\\left(s, a^{\\prime}\\right)}$$\n",
    "\n",
    "#### 代码估计\n",
    "注意：以上提到的“合法”占用度量是指存在一个策略使智能体与 MDP 交互产生的状态动作对被访问到的概率。\n",
    "\n",
    "接下来我们编写代码来近似估计占用度量。这里我们采用近似估计，即设置一个较大的采样轨迹长度的最大值，然后采样很多次，用状态动作对出现的频率估计实际概率。\n",
    "```python\n",
    "def occupancy(episodes, s, a, timestep_max, gamma):\n",
    "    ''' 计算状态动作对（s,a）出现的频率,以此来估算策略的占用度量 '''\n",
    "    rho = 0\n",
    "    total_times = np.zeros(timestep_max)  # 记录每个时间步t各被经历过几次\n",
    "    occur_times = np.zeros(timestep_max)  # 记录(s_t,a_t)=(s,a)的次数\n",
    "    for episode in episodes:\n",
    "        for i in range(len(episode)):\n",
    "            (s_opt, a_opt, r, s_next) = episode[i]\n",
    "            total_times[i] += 1\n",
    "            if s == s_opt and a == a_opt:\n",
    "                occur_times[i] += 1\n",
    "    for i in reversed(range(timestep_max)):\n",
    "        if total_times[i]:\n",
    "            rho += gamma**i * occur_times[i] / total_times[i]\n",
    "    return (1 - gamma) * rho\n",
    "\n",
    "\n",
    "gamma = 0.5\n",
    "timestep_max = 1000\n",
    "\n",
    "episodes_1 = sample(MDP, Pi_1, timestep_max, 1000)\n",
    "episodes_2 = sample(MDP, Pi_2, timestep_max, 1000)\n",
    "rho_1 = occupancy(episodes_1, \"s4\", \"概率前往\", timestep_max, gamma)\n",
    "rho_2 = occupancy(episodes_2, \"s4\", \"概率前往\", timestep_max, gamma)\n",
    "print(rho_1, rho_2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2200da",
   "metadata": {},
   "source": [
    "您给出的状态访问分布和占用度量的定义是在考虑了折扣因子 $ \\gamma $ 的情况下的定义。在您给出的定义中，折扣因子 $ \\gamma $ 被用来对未来的状态和动作进行折扣，这样使得近期的状态和动作比远期的更重要。\n",
    "\n",
    "我之前给出的定义是更为通用的定义，没有明确包括折扣因子。但两者的核心思想是相同的：描述在给定策略下，状态或状态-动作对被访问的分布。\n",
    "\n",
    "现在，让我们对比一下两个定义：\n",
    "\n",
    "1. **状态访问分布**:\n",
    "   - 我给出的定义主要基于状态转移概率和策略的递归关系来定义。\n",
    "   - 您给出的定义是考虑了时间和折扣因子的，表达了在无限时间内，状态被访问的期望频率。\n",
    "\n",
    "2. **占用度量**:\n",
    "   - 我给出的定义是状态访问分布和在给定状态下采取特定动作的概率的乘积。\n",
    "   - 您给出的定义同样是基于时间和折扣因子，表达了在无限时间内，状态-动作对被访问的期望频率。\n",
    "\n",
    "您给出的两个定理是基于占用度量和状态访问分布的关系的。这两个定理描述了占用度量、策略和状态访问分布之间的一些重要性质。\n",
    "\n",
    "总之，虽然两种定义在形式上有所不同，但它们都是为了描述同一核心概念。您给出的定义在某些特定的研究背景和应用中可能更为合适，特别是当考虑时间和折扣因子的影响时。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206f69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
